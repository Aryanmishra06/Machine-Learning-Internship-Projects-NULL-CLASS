{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Car Color Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07V16HQl4hE3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical # pyright: ignore[reportMissingImports]\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0INM9nQR5ne",
        "outputId": "9142b6c8-9d50-4458-bf14-034f9d6293bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/landrykezebou/vcor-vehicle-color-recognition-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 574M/574M [00:28<00:00, 21.2MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/landrykezebou/vcor-vehicle-color-recognition-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub # pyright: ignore[reportMissingImports]\n",
        "\n",
        "\n",
        "path = kagglehub.dataset_download(\"landrykezebou/vcor-vehicle-color-recognition-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMBO9xZY4ZxZ"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/root/.cache/kagglehub/datasets/landrykezebou/vcor-vehicle-color-recognition-dataset/versions/1\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLJp1mHr4i3O",
        "outputId": "bb3a3436-e7f8-4021-c118-75672c07d1c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          image_path  blue  other\n",
            "0  /root/.cache/kagglehub/datasets/landrykezebou/...     1      0\n",
            "1  /root/.cache/kagglehub/datasets/landrykezebou/...     1      0\n",
            "2  /root/.cache/kagglehub/datasets/landrykezebou/...     1      0\n",
            "3  /root/.cache/kagglehub/datasets/landrykezebou/...     1      0\n",
            "4  /root/.cache/kagglehub/datasets/landrykezebou/...     1      0\n",
            "Total samples: 10373\n",
            "Blue images: 1060\n",
            "Other images: 9313\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd # pyright: ignore[reportMissingModuleSource]\n",
        "\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/landrykezebou/vcor-vehicle-color-recognition-dataset/versions/1\"\n",
        "folders = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "data = []\n",
        "\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(dataset_path, folder)\n",
        "    for class_name in os.listdir(folder_path):\n",
        "        class_folder = os.path.join(folder_path, class_name)\n",
        "        if not os.path.isdir(class_folder):\n",
        "            continue\n",
        "        for img_name in os.listdir(class_folder):\n",
        "            img_path = os.path.join(class_folder, img_name)\n",
        "            # Define labels\n",
        "            blue = 1 if class_name == \"blue\" else 0\n",
        "            other = 1 if class_name != \"blue\" else 0\n",
        "            data.append([img_path, blue, other])\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"image_path\", \"blue\", \"other\"])\n",
        "\n",
        "# Show first few rows\n",
        "print(df.head())\n",
        "print(\"Total samples:\", len(df))\n",
        "print(\"Blue images:\", df['blue'].sum())\n",
        "print(\"Other images:\", df['other'].sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnjh3XIN4kgy",
        "outputId": "503314ca-8b3c-45a5-d518-57186621bec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 10373\n",
            "Blue images: 1060\n",
            "Other images: 9313\n",
            "Training samples: 8298 Testing samples: 2075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.9345 - loss: 0.1599 - val_accuracy: 0.9802 - val_loss: 0.0577\n",
            "Epoch 2/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9797 - loss: 0.0645 - val_accuracy: 0.9846 - val_loss: 0.0460\n",
            "Epoch 3/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0422 - val_accuracy: 0.9875 - val_loss: 0.0326\n",
            "Epoch 4/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0456 - val_accuracy: 0.9870 - val_loss: 0.0339\n",
            "Epoch 5/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0363 - val_accuracy: 0.9884 - val_loss: 0.0324\n",
            "Epoch 6/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0437 - val_accuracy: 0.9908 - val_loss: 0.0285\n",
            "Epoch 7/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9901 - loss: 0.0322 - val_accuracy: 0.9908 - val_loss: 0.0274\n",
            "Epoch 8/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0306 - val_accuracy: 0.9908 - val_loss: 0.0301\n",
            "Epoch 9/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.0282 - val_accuracy: 0.9913 - val_loss: 0.0232\n",
            "Epoch 10/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0219 - val_accuracy: 0.9918 - val_loss: 0.0387\n",
            "Epoch 11/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0243 - val_accuracy: 0.9870 - val_loss: 0.0432\n",
            "Epoch 12/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0190 - val_accuracy: 0.9913 - val_loss: 0.0379\n",
            "Epoch 13/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0176 - val_accuracy: 0.9913 - val_loss: 0.0326\n",
            "Epoch 14/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0131 - val_accuracy: 0.9841 - val_loss: 0.0525\n",
            "Epoch 15/15\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0239 - val_accuracy: 0.9899 - val_loss: 0.0467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as car_color_blue_other.h5\n"
          ]
        }
      ],
      "source": [
        "# cnn_blue_other.py\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ---------------- Parameters ----------------\n",
        "IMG_SIZE = 64\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/landrykezebou/vcor-vehicle-color-recognition-dataset/versions/1\"\n",
        "folders = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "# ---------------- Create DataFrame ----------------\n",
        "data = []\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(dataset_path, folder)\n",
        "    for class_name in os.listdir(folder_path):\n",
        "        class_folder = os.path.join(folder_path, class_name)\n",
        "        if not os.path.isdir(class_folder):\n",
        "            continue\n",
        "        for img_name in os.listdir(class_folder):\n",
        "            img_path = os.path.join(class_folder, img_name)\n",
        "            blue = 1 if class_name == \"blue\" else 0\n",
        "            other = 1 if class_name != \"blue\" else 0\n",
        "            label = 0 if class_name == \"blue\" else 1  # 0=blue, 1=other\n",
        "            data.append([img_path, label])\n",
        "\n",
        "df = pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n",
        "print(\"Total samples:\", len(df))\n",
        "print(\"Blue images:\", sum(df['label']==0))\n",
        "print(\"Other images:\", sum(df['label']==1))\n",
        "\n",
        "# ---------------- Load Images ----------------\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    img = cv2.imread(row['image_path'])\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        images.append(img)\n",
        "        labels.append(row['label'])\n",
        "\n",
        "X = np.array(images, dtype=\"float32\") / 255.0\n",
        "y = to_categorical(np.array(labels), num_classes=2)\n",
        "\n",
        "# ---------------- Train/Test Split ----------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(\"Training samples:\", len(X_train), \"Testing samples:\", len(X_test))\n",
        "\n",
        "# ---------------- CNN Model ----------------\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')  # 2 classes: blue, other\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# ---------------- Train Model ----------------\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size=BATCH_SIZE)\n",
        "\n",
        "# ---------------- Save Model ----------------\n",
        "model.save(\"car_color_blue_other.h5\")\n",
        "print(\"Model saved as car_color_blue_other.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_MRWspW7ydP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
